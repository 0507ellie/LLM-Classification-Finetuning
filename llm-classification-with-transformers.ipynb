{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c3977d1",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-21T05:05:54.219395Z",
     "iopub.status.busy": "2025-08-21T05:05:54.219122Z",
     "iopub.status.idle": "2025-08-21T05:05:55.841532Z",
     "shell.execute_reply": "2025-08-21T05:05:55.840465Z"
    },
    "papermill": {
     "duration": 1.631118,
     "end_time": "2025-08-21T05:05:55.842950",
     "exception": false,
     "start_time": "2025-08-21T05:05:54.211832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/distilbertbaseuncased/rust_model.ot\n",
      "/kaggle/input/distilbertbaseuncased/config.json\n",
      "/kaggle/input/distilbertbaseuncased/README.md\n",
      "/kaggle/input/distilbertbaseuncased/tokenizer.json\n",
      "/kaggle/input/distilbertbaseuncased/tf_model.h5\n",
      "/kaggle/input/distilbertbaseuncased/tokenizer_config.json\n",
      "/kaggle/input/distilbertbaseuncased/pytorch_model.bin\n",
      "/kaggle/input/distilbertbaseuncased/.gitattributes\n",
      "/kaggle/input/distilbertbaseuncased/vocab.txt\n",
      "/kaggle/input/distilbertbaseuncased/flax_model.msgpack\n",
      "/kaggle/input/llm-classification-finetuning/sample_submission.csv\n",
      "/kaggle/input/llm-classification-finetuning/train.csv\n",
      "/kaggle/input/llm-classification-finetuning/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8af9f6",
   "metadata": {
    "papermill": {
     "duration": 0.005046,
     "end_time": "2025-08-21T05:05:55.853516",
     "exception": false,
     "start_time": "2025-08-21T05:05:55.848470",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7783716",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T05:05:55.864540Z",
     "iopub.status.busy": "2025-08-21T05:05:55.864217Z",
     "iopub.status.idle": "2025-08-21T05:06:04.698201Z",
     "shell.execute_reply": "2025-08-21T05:06:04.697312Z"
    },
    "papermill": {
     "duration": 8.841413,
     "end_time": "2025-08-21T05:06:04.699943",
     "exception": false,
     "start_time": "2025-08-21T05:05:55.858530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b393e26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T05:06:04.711841Z",
     "iopub.status.busy": "2025-08-21T05:06:04.711387Z",
     "iopub.status.idle": "2025-08-21T05:06:04.780076Z",
     "shell.execute_reply": "2025-08-21T05:06:04.779230Z"
    },
    "papermill": {
     "duration": 0.07562,
     "end_time": "2025-08-21T05:06:04.781280",
     "exception": false,
     "start_time": "2025-08-21T05:06:04.705660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f13f6a17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T05:06:04.792530Z",
     "iopub.status.busy": "2025-08-21T05:06:04.792283Z",
     "iopub.status.idle": "2025-08-21T05:06:08.226929Z",
     "shell.execute_reply": "2025-08-21T05:06:08.225768Z"
    },
    "papermill": {
     "duration": 3.441622,
     "end_time": "2025-08-21T05:06:08.228274",
     "exception": false,
     "start_time": "2025-08-21T05:06:04.786652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (57477, 9)\n",
      "Test shape: (3, 4)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "train_df = pd.read_csv('/kaggle/input/llm-classification-finetuning/train.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/llm-classification-finetuning/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7afa9a43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T05:06:08.239798Z",
     "iopub.status.busy": "2025-08-21T05:06:08.239518Z",
     "iopub.status.idle": "2025-08-21T05:06:08.256694Z",
     "shell.execute_reply": "2025-08-21T05:06:08.255763Z"
    },
    "papermill": {
     "duration": 0.024317,
     "end_time": "2025-08-21T05:06:08.258024",
     "exception": false,
     "start_time": "2025-08-21T05:06:08.233707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target distribution:\n",
      "target\n",
      "0    20064\n",
      "1    19652\n",
      "2    17761\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create target variable\n",
    "train_df['target'] = 0  # model_a wins\n",
    "train_df.loc[train_df['winner_model_b'] == 1, 'target'] = 1  # model_b wins\n",
    "train_df.loc[train_df['winner_tie'] == 1, 'target'] = 2  # tie\n",
    "\n",
    "print(\"Target distribution:\")\n",
    "print(train_df['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14bc74c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T05:06:08.270099Z",
     "iopub.status.busy": "2025-08-21T05:06:08.269860Z",
     "iopub.status.idle": "2025-08-21T05:06:30.100926Z",
     "shell.execute_reply": "2025-08-21T05:06:30.100251Z"
    },
    "papermill": {
     "duration": 21.837999,
     "end_time": "2025-08-21T05:06:30.102399",
     "exception": false,
     "start_time": "2025-08-21T05:06:08.264400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 05:06:15.981484: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1755752776.180342      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1755752776.235984      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "\n",
    "# Use the dataset path instead of downloading\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('/kaggle/input/distilbertbaseuncased')\n",
    "model = DistilBertModel.from_pretrained('/kaggle/input/distilbertbaseuncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4722c87d",
   "metadata": {
    "papermill": {
     "duration": 0.004987,
     "end_time": "2025-08-21T05:06:30.112985",
     "exception": false,
     "start_time": "2025-08-21T05:06:30.107998",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Preprocess for transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce804262",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T05:06:30.124552Z",
     "iopub.status.busy": "2025-08-21T05:06:30.124038Z",
     "iopub.status.idle": "2025-08-21T05:06:30.129796Z",
     "shell.execute_reply": "2025-08-21T05:06:30.129173Z"
    },
    "papermill": {
     "duration": 0.012792,
     "end_time": "2025-08-21T05:06:30.131024",
     "exception": false,
     "start_time": "2025-08-21T05:06:30.118232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_text_for_transformer(df, tokenizer, max_length=512):\n",
    "    \"\"\"\n",
    "    Prepare text data for transformer models\n",
    "    We'll combine prompt + response_a + response_b into single input\n",
    "    \"\"\"\n",
    "    print(\"Preparing text for transformer...\")\n",
    "    \n",
    "    # Create combined text for each conversation\n",
    "    # Format: [CLS] prompt [SEP] response_a [SEP] response_b [SEP]\n",
    "    combined_texts = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        # Clean and truncate text to avoid memory issues\n",
    "        prompt = str(row['prompt'])[:200]  # Limit prompt length\n",
    "        response_a = str(row['response_a'])[:300]  # Limit response length\n",
    "        response_b = str(row['response_b'])[:300]\n",
    "        \n",
    "        # Combine with special tokens\n",
    "        combined_text = f\"{prompt} [SEP] {response_a} [SEP] {response_b}\"\n",
    "        combined_texts.append(combined_text)\n",
    "    \n",
    "    # Tokenize all texts\n",
    "    print(\"Tokenizing texts...\")\n",
    "    tokenized = tokenizer(\n",
    "        combined_texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    print(f\"Tokenized shape: {tokenized['input_ids'].shape}\")\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2382709e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T05:06:30.143422Z",
     "iopub.status.busy": "2025-08-21T05:06:30.143194Z",
     "iopub.status.idle": "2025-08-21T05:06:41.557389Z",
     "shell.execute_reply": "2025-08-21T05:06:41.556385Z"
    },
    "papermill": {
     "duration": 11.422787,
     "end_time": "2025-08-21T05:06:41.558849",
     "exception": false,
     "start_time": "2025-08-21T05:06:30.136062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using sample of 5000 conversations for demo\n",
      "Preparing text for transformer...\n",
      "Tokenizing texts...\n",
      "Tokenized shape: torch.Size([5000, 512])\n",
      "Preparing text for transformer...\n",
      "Tokenizing texts...\n",
      "Tokenized shape: torch.Size([3, 193])\n",
      "Section 2 complete - Text preprocessing done!\n"
     ]
    }
   ],
   "source": [
    "sample_size = 5000  # Reduce for faster training\n",
    "train_sample = train_df.head(sample_size).copy()\n",
    "\n",
    "print(f\"Using sample of {len(train_sample)} conversations for demo\")\n",
    "\n",
    "# Prepare training data\n",
    "train_tokenized = prepare_text_for_transformer(train_sample, tokenizer, max_length=512)\n",
    "\n",
    "# Prepare test data (all of it since it's small)\n",
    "test_tokenized = prepare_text_for_transformer(test_df, tokenizer, max_length=512)\n",
    "\n",
    "print(\"Section 2 complete - Text preprocessing done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2991acc4",
   "metadata": {
    "papermill": {
     "duration": 0.005419,
     "end_time": "2025-08-21T05:06:41.570313",
     "exception": false,
     "start_time": "2025-08-21T05:06:41.564894",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Create Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ff3e0bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T05:06:41.582703Z",
     "iopub.status.busy": "2025-08-21T05:06:41.582424Z",
     "iopub.status.idle": "2025-08-21T05:06:41.590461Z",
     "shell.execute_reply": "2025-08-21T05:06:41.589578Z"
    },
    "papermill": {
     "duration": 0.01578,
     "end_time": "2025-08-21T05:06:41.591715",
     "exception": false,
     "start_time": "2025-08-21T05:06:41.575935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import AutoModel\n",
    "\n",
    "class ChatbotPreferenceModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Extremely conservative model to prevent overfitting\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name='distilbert-base-uncased', num_classes=3):\n",
    "        super(ChatbotPreferenceModel, self).__init__()\n",
    "        \n",
    "        self.transformer = AutoModel.from_pretrained(model_name)\n",
    "        hidden_size = self.transformer.config.hidden_size\n",
    "        \n",
    "        # EXTREME regularization\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.8),                    # VERY HIGH dropout\n",
    "            nn.Linear(hidden_size, num_classes) # Direct to output - NO hidden layers\n",
    "        )\n",
    "        \n",
    "        # FREEZE ALMOST EVERYTHING\n",
    "        for param in self.transformer.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        # Only train the VERY LAST attention layer\n",
    "        for param in self.transformer.transformer.layer[-1].attention.parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "        print(\"ðŸ”’ ULTRA-CONSERVATIVE: Froze entire transformer except final attention layer\")\n",
    "        \n",
    "        # Count trainable parameters\n",
    "        trainable = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "        total = sum(p.numel() for p in self.parameters())\n",
    "        print(f\"ðŸ“Š Trainable: {trainable:,} / {total:,} ({100*trainable/total:.1f}%)\")\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Get transformer outputs\n",
    "        outputs = self.transformer(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Use [CLS] token representation (first token)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]\n",
    "        \n",
    "        # Pass through classifier\n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "753e42c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T05:06:41.604347Z",
     "iopub.status.busy": "2025-08-21T05:06:41.604033Z",
     "iopub.status.idle": "2025-08-21T05:06:47.263180Z",
     "shell.execute_reply": "2025-08-21T05:06:47.262217Z"
    },
    "papermill": {
     "duration": 5.667062,
     "end_time": "2025-08-21T05:06:47.264418",
     "exception": false,
     "start_time": "2025-08-21T05:06:41.597356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating transformer model...\n",
      "ðŸ”’ ULTRA-CONSERVATIVE: Froze entire transformer except final attention layer\n",
      "ðŸ“Š Trainable: 2,364,675 / 66,365,187 (3.6%)\n",
      "Total parameters: 66,365,187\n",
      "Trainable parameters: 2,364,675\n",
      "Section 3 complete - Model created!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize model\n",
    "print(\"Creating transformer model...\")\n",
    "model = ChatbotPreferenceModel(model_name = '/kaggle/input/distilbertbaseuncased', num_classes=3)\n",
    "model.to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "print(\"Section 3 complete - Model created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bb0e04",
   "metadata": {
    "papermill": {
     "duration": 0.005371,
     "end_time": "2025-08-21T05:06:47.275551",
     "exception": false,
     "start_time": "2025-08-21T05:06:47.270180",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7972f957",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T05:06:47.287658Z",
     "iopub.status.busy": "2025-08-21T05:06:47.287353Z",
     "iopub.status.idle": "2025-08-21T05:06:47.319016Z",
     "shell.execute_reply": "2025-08-21T05:06:47.318243Z"
    },
    "papermill": {
     "duration": 0.039356,
     "end_time": "2025-08-21T05:06:47.320317",
     "exception": false,
     "start_time": "2025-08-21T05:06:47.280961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "class ChatbotDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset for chatbot preference data\n",
    "    \"\"\"\n",
    "    def __init__(self, tokenized_data, targets=None):\n",
    "        self.input_ids = tokenized_data['input_ids']\n",
    "        self.attention_mask = tokenized_data['attention_mask']\n",
    "        self.targets = targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {\n",
    "            'input_ids': self.input_ids[idx],\n",
    "            'attention_mask': self.attention_mask[idx]\n",
    "        }\n",
    "        \n",
    "        if self.targets is not None:\n",
    "            item['targets'] = torch.tensor(self.targets[idx], dtype=torch.long)\n",
    "        \n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "420fc54e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T05:06:47.332338Z",
     "iopub.status.busy": "2025-08-21T05:06:47.332093Z",
     "iopub.status.idle": "2025-08-21T05:06:47.342205Z",
     "shell.execute_reply": "2025-08-21T05:06:47.341330Z"
    },
    "papermill": {
     "duration": 0.017455,
     "end_time": "2025-08-21T05:06:47.343311",
     "exception": false,
     "start_time": "2025-08-21T05:06:47.325856",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 4000\n",
      "Validation size: 1000\n"
     ]
    }
   ],
   "source": [
    "# Split training data\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    range(len(train_sample)), \n",
    "    train_sample['target'].values,\n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=train_sample['target'].values\n",
    ")\n",
    "\n",
    "print(f\"Train size: {len(X_train)}\")\n",
    "print(f\"Validation size: {len(X_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffdb407a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T05:06:47.354991Z",
     "iopub.status.busy": "2025-08-21T05:06:47.354706Z",
     "iopub.status.idle": "2025-08-21T05:06:47.369961Z",
     "shell.execute_reply": "2025-08-21T05:06:47.369260Z"
    },
    "papermill": {
     "duration": 0.022537,
     "end_time": "2025-08-21T05:06:47.371417",
     "exception": false,
     "start_time": "2025-08-21T05:06:47.348880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create subset of tokenized data for train/val split\n",
    "train_input_ids = train_tokenized['input_ids'][X_train]\n",
    "train_attention_mask = train_tokenized['attention_mask'][X_train]\n",
    "train_tokenized_subset = {'input_ids': train_input_ids, 'attention_mask': train_attention_mask}\n",
    "\n",
    "val_input_ids = train_tokenized['input_ids'][X_val]\n",
    "val_attention_mask = train_tokenized['attention_mask'][X_val]\n",
    "val_tokenized_subset = {'input_ids': val_input_ids, 'attention_mask': val_attention_mask}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98f58b11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T05:06:47.383544Z",
     "iopub.status.busy": "2025-08-21T05:06:47.383299Z",
     "iopub.status.idle": "2025-08-21T05:06:47.387456Z",
     "shell.execute_reply": "2025-08-21T05:06:47.386675Z"
    },
    "papermill": {
     "duration": 0.0114,
     "end_time": "2025-08-21T05:06:47.388585",
     "exception": false,
     "start_time": "2025-08-21T05:06:47.377185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = ChatbotDataset(train_tokenized_subset, y_train)\n",
    "val_dataset = ChatbotDataset(val_tokenized_subset, y_val)\n",
    "test_dataset = ChatbotDataset(test_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ce0e213",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T05:06:47.399717Z",
     "iopub.status.busy": "2025-08-21T05:06:47.399480Z",
     "iopub.status.idle": "2025-08-21T05:06:47.404581Z",
     "shell.execute_reply": "2025-08-21T05:06:47.403819Z"
    },
    "papermill": {
     "duration": 0.012109,
     "end_time": "2025-08-21T05:06:47.405838",
     "exception": false,
     "start_time": "2025-08-21T05:06:47.393729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 125\n",
      "Val batches: 32\n",
      "Test batches: 1\n"
     ]
    }
   ],
   "source": [
    "# Create data loaders\n",
    "batch_size = 32  # Adjust based on GPU memory\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fe45d83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T05:06:47.417536Z",
     "iopub.status.busy": "2025-08-21T05:06:47.417090Z",
     "iopub.status.idle": "2025-08-21T05:06:47.422122Z",
     "shell.execute_reply": "2025-08-21T05:06:47.421494Z"
    },
    "papermill": {
     "duration": 0.011971,
     "end_time": "2025-08-21T05:06:47.423176",
     "exception": false,
     "start_time": "2025-08-21T05:06:47.411205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup optimizer and scheduler\n",
    "learning_rate = 0.01 # Lower learning rate for pre-trained models\n",
    "num_epochs = 25  \n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=0.3)\n",
    "\n",
    "# Calculate total training steps\n",
    "total_steps = len(train_loader) * num_epochs\n",
    "\n",
    "# Setup learning rate scheduler\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0.1 * total_steps,  # 10% warmup\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caa417a",
   "metadata": {
    "papermill": {
     "duration": 0.005018,
     "end_time": "2025-08-21T05:06:47.433377",
     "exception": false,
     "start_time": "2025-08-21T05:06:47.428359",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b83f99a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T05:06:47.444894Z",
     "iopub.status.busy": "2025-08-21T05:06:47.444277Z",
     "iopub.status.idle": "2025-08-21T05:06:47.451531Z",
     "shell.execute_reply": "2025-08-21T05:06:47.450992Z"
    },
    "papermill": {
     "duration": 0.01432,
     "end_time": "2025-08-21T05:06:47.452800",
     "exception": false,
     "start_time": "2025-08-21T05:06:47.438480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_epoch(model, train_loader, optimizer, scheduler, criterion, device):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=\"Training\")\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        # Move batch to device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        targets = batch['targets'].to(device)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        logits = model(input_ids, attention_mask)\n",
    "        loss = criterion(logits, targets)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping to prevent exploding gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        correct_predictions += (predictions == targets).sum().item()\n",
    "        total_predictions += targets.size(0)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'acc': f'{correct_predictions/total_predictions:.4f}'\n",
    "        })\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    \n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9a79215",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T05:06:47.464275Z",
     "iopub.status.busy": "2025-08-21T05:06:47.464082Z",
     "iopub.status.idle": "2025-08-21T05:06:47.470034Z",
     "shell.execute_reply": "2025-08-21T05:06:47.469502Z"
    },
    "papermill": {
     "duration": 0.012919,
     "end_time": "2025-08-21T05:06:47.471206",
     "exception": false,
     "start_time": "2025-08-21T05:06:47.458287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader, criterion, device):\n",
    "    \"\"\"Evaluate model\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_predictions = []\n",
    "    all_probabilities = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            targets = batch['targets'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            logits = model(input_ids, attention_mask)\n",
    "            loss = criterion(logits, targets)\n",
    "            \n",
    "            # Get probabilities\n",
    "            probabilities = F.softmax(logits, dim=-1)\n",
    "            predictions = torch.argmax(logits, dim=-1)\n",
    "            \n",
    "            # Collect results\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_probabilities.extend(probabilities.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    accuracy = accuracy_score(all_targets, all_predictions)\n",
    "    \n",
    "    # Calculate log loss\n",
    "    log_loss_score = log_loss(all_targets, all_probabilities)\n",
    "    \n",
    "    return avg_loss, accuracy, log_loss_score, all_probabilities, all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4cf6fe7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T05:06:47.484599Z",
     "iopub.status.busy": "2025-08-21T05:06:47.483895Z",
     "iopub.status.idle": "2025-08-21T05:28:50.997589Z",
     "shell.execute_reply": "2025-08-21T05:28:50.996652Z"
    },
    "papermill": {
     "duration": 1323.521668,
     "end_time": "2025-08-21T05:28:50.998853",
     "exception": false,
     "start_time": "2025-08-21T05:06:47.477185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "\n",
      "Epoch 1/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:44<00:00,  2.79it/s, loss=1.1022, acc=0.3417]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:07<00:00,  4.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1637 | Train Acc: 0.3417\n",
      "Val Loss: 1.1118 | Val Acc: 0.3400 | Val Log Loss: 1.1103\n",
      "New best model! Log Loss: 1.1103\n",
      "\n",
      "Epoch 2/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:44<00:00,  2.78it/s, loss=1.1268, acc=0.3563]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:07<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2173 | Train Acc: 0.3563\n",
      "Val Loss: 1.1072 | Val Acc: 0.3340 | Val Log Loss: 1.1051\n",
      "New best model! Log Loss: 1.1051\n",
      "\n",
      "Epoch 3/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:45<00:00,  2.77it/s, loss=1.3672, acc=0.3360]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:07<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2600 | Train Acc: 0.3360\n",
      "Val Loss: 1.1309 | Val Acc: 0.3230 | Val Log Loss: 1.1275\n",
      "\n",
      "Epoch 4/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:45<00:00,  2.77it/s, loss=1.2885, acc=0.3422]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:07<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2518 | Train Acc: 0.3422\n",
      "Val Loss: 1.1444 | Val Acc: 0.3070 | Val Log Loss: 1.1471\n",
      "\n",
      "Epoch 5/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:45<00:00,  2.77it/s, loss=1.1850, acc=0.3385]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:07<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1978 | Train Acc: 0.3385\n",
      "Val Loss: 1.1163 | Val Acc: 0.3070 | Val Log Loss: 1.1182\n",
      "\n",
      "Epoch 6/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:45<00:00,  2.77it/s, loss=1.1907, acc=0.3443]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:07<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2048 | Train Acc: 0.3443\n",
      "Val Loss: 1.0987 | Val Acc: 0.3860 | Val Log Loss: 1.0975\n",
      "New best model! Log Loss: 1.0975\n",
      "\n",
      "Epoch 7/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:45<00:00,  2.77it/s, loss=1.1896, acc=0.3513]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:07<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1873 | Train Acc: 0.3513\n",
      "Val Loss: 1.1098 | Val Acc: 0.3540 | Val Log Loss: 1.1078\n",
      "\n",
      "Epoch 8/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:45<00:00,  2.77it/s, loss=1.0540, acc=0.3377]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:07<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1983 | Train Acc: 0.3377\n",
      "Val Loss: 1.1341 | Val Acc: 0.3400 | Val Log Loss: 1.1312\n",
      "\n",
      "Epoch 9/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:45<00:00,  2.77it/s, loss=1.2697, acc=0.3533]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:07<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1575 | Train Acc: 0.3533\n",
      "Val Loss: 1.1391 | Val Acc: 0.3530 | Val Log Loss: 1.1374\n",
      "\n",
      "Epoch 10/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:45<00:00,  2.77it/s, loss=1.1269, acc=0.3327]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:07<00:00,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1713 | Train Acc: 0.3327\n",
      "Val Loss: 1.1158 | Val Acc: 0.3400 | Val Log Loss: 1.1134\n",
      "\n",
      "Epoch 11/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:45<00:00,  2.77it/s, loss=1.1611, acc=0.3495]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:07<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1591 | Train Acc: 0.3495\n",
      "Val Loss: 1.1798 | Val Acc: 0.3070 | Val Log Loss: 1.1836\n",
      "\n",
      "Epoch 12/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:45<00:00,  2.77it/s, loss=1.0365, acc=0.3397]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:07<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1635 | Train Acc: 0.3397\n",
      "Val Loss: 1.1173 | Val Acc: 0.3150 | Val Log Loss: 1.1179\n",
      "\n",
      "Epoch 13/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:45<00:00,  2.77it/s, loss=1.1908, acc=0.3347]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:07<00:00,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1438 | Train Acc: 0.3347\n",
      "Val Loss: 1.0963 | Val Acc: 0.3580 | Val Log Loss: 1.0977\n",
      "\n",
      "Epoch 14/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:45<00:00,  2.77it/s, loss=1.0646, acc=0.3503]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:07<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1381 | Train Acc: 0.3503\n",
      "Val Loss: 1.1036 | Val Acc: 0.3440 | Val Log Loss: 1.1021\n",
      "\n",
      "Epoch 15/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:45<00:00,  2.77it/s, loss=1.1116, acc=0.3668]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:07<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1272 | Train Acc: 0.3668\n",
      "Val Loss: 1.1022 | Val Acc: 0.3500 | Val Log Loss: 1.1014\n",
      "\n",
      "Epoch 16/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:45<00:00,  2.77it/s, loss=1.0718, acc=0.3495]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:07<00:00,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1312 | Train Acc: 0.3495\n",
      "Val Loss: 1.0966 | Val Acc: 0.3190 | Val Log Loss: 1.0975\n",
      "\n",
      "Epoch 17/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:45<00:00,  2.77it/s, loss=1.1489, acc=0.3750]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:07<00:00,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1150 | Train Acc: 0.3750\n",
      "Val Loss: 1.1126 | Val Acc: 0.3510 | Val Log Loss: 1.1128\n",
      "\n",
      "Epoch 18/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:45<00:00,  2.77it/s, loss=1.0847, acc=0.3673]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:07<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1097 | Train Acc: 0.3673\n",
      "Val Loss: 1.1150 | Val Acc: 0.3480 | Val Log Loss: 1.1126\n",
      "\n",
      "Epoch 19/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:45<00:00,  2.77it/s, loss=1.1213, acc=0.3972]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:07<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0991 | Train Acc: 0.3972\n",
      "Val Loss: 1.1137 | Val Acc: 0.3670 | Val Log Loss: 1.1154\n",
      "\n",
      "Epoch 20/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:45<00:00,  2.77it/s, loss=1.1575, acc=0.3895]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:07<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0916 | Train Acc: 0.3895\n",
      "Val Loss: 1.1187 | Val Acc: 0.3640 | Val Log Loss: 1.1193\n",
      "\n",
      "Epoch 21/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:45<00:00,  2.77it/s, loss=1.0079, acc=0.3917]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:07<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0824 | Train Acc: 0.3917\n",
      "Val Loss: 1.1036 | Val Acc: 0.3630 | Val Log Loss: 1.1047\n",
      "\n",
      "Epoch 22/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:45<00:00,  2.77it/s, loss=1.1591, acc=0.4253]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:07<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0601 | Train Acc: 0.4253\n",
      "Val Loss: 1.1167 | Val Acc: 0.3720 | Val Log Loss: 1.1165\n",
      "\n",
      "Epoch 23/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:45<00:00,  2.77it/s, loss=1.0036, acc=0.4422]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:07<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0567 | Train Acc: 0.4422\n",
      "Val Loss: 1.1291 | Val Acc: 0.3650 | Val Log Loss: 1.1314\n",
      "\n",
      "Epoch 24/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:45<00:00,  2.77it/s, loss=1.0890, acc=0.4600]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:07<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0396 | Train Acc: 0.4600\n",
      "Val Loss: 1.1259 | Val Acc: 0.3780 | Val Log Loss: 1.1312\n",
      "\n",
      "Epoch 25/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:45<00:00,  2.77it/s, loss=1.1060, acc=0.4748]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:07<00:00,  4.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0225 | Train Acc: 0.4748\n",
      "Val Loss: 1.1322 | Val Acc: 0.3830 | Val Log Loss: 1.1379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "print(\"Starting training...\")\n",
    "best_log_loss = float('inf')\n",
    "best_model_state = None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, optimizer, scheduler, criterion, device)\n",
    "    \n",
    "    # Evaluate\n",
    "    val_loss, val_acc, val_log_loss, _, _ = evaluate(model, val_loader, criterion, device)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | Val Log Loss: {val_log_loss:.4f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_log_loss < best_log_loss:\n",
    "        best_log_loss = val_log_loss\n",
    "        best_model_state = model.state_dict().copy()\n",
    "        print(f\"New best model! Log Loss: {best_log_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74cb69f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T05:28:51.644753Z",
     "iopub.status.busy": "2025-08-21T05:28:51.644445Z",
     "iopub.status.idle": "2025-08-21T05:28:51.652083Z",
     "shell.execute_reply": "2025-08-21T05:28:51.651296Z"
    },
    "papermill": {
     "duration": 0.359252,
     "end_time": "2025-08-21T05:28:51.653161",
     "exception": false,
     "start_time": "2025-08-21T05:28:51.293909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded best model with log loss: 1.0975\n"
     ]
    }
   ],
   "source": [
    "# Load best model\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(f\"\\nLoaded best model with log loss: {best_log_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31c761e",
   "metadata": {
    "papermill": {
     "duration": 0.281818,
     "end_time": "2025-08-21T05:28:52.230198",
     "exception": false,
     "start_time": "2025-08-21T05:28:51.948380",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7381c123",
   "metadata": {
    "papermill": {
     "duration": 0.290277,
     "end_time": "2025-08-21T05:28:52.803819",
     "exception": false,
     "start_time": "2025-08-21T05:28:52.513542",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1897c83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T05:28:53.430068Z",
     "iopub.status.busy": "2025-08-21T05:28:53.429791Z",
     "iopub.status.idle": "2025-08-21T05:28:53.454351Z",
     "shell.execute_reply": "2025-08-21T05:28:53.453321Z"
    },
    "papermill": {
     "duration": 0.312354,
     "end_time": "2025-08-21T05:28:53.455681",
     "exception": false,
     "start_time": "2025-08-21T05:28:53.143327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Making predictions: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 67.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test predictions shape: (3, 3)\n",
      "First few predictions:\n",
      "[[0.25520962 0.2073963  0.53739405]\n",
      " [0.5597395  0.32862967 0.11163091]\n",
      " [0.294327   0.4047011  0.30097187]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def make_predictions(model, test_loader, device):\n",
    "    \"\"\"Make predictions on test set\"\"\"\n",
    "    model.eval()\n",
    "    all_probabilities = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Making predictions\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            logits = model(input_ids, attention_mask)\n",
    "            \n",
    "            # Get probabilities\n",
    "            probabilities = F.softmax(logits, dim=-1)\n",
    "            all_probabilities.extend(probabilities.cpu().numpy())\n",
    "    \n",
    "    return np.array(all_probabilities)\n",
    "\n",
    "# Make predictions on test set\n",
    "print(\"Making predictions on test set...\")\n",
    "test_predictions = make_predictions(model, test_loader, device)\n",
    "\n",
    "print(f\"Test predictions shape: {test_predictions.shape}\")\n",
    "print(f\"First few predictions:\")\n",
    "print(test_predictions[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50d39558",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T05:28:54.029466Z",
     "iopub.status.busy": "2025-08-21T05:28:54.029167Z",
     "iopub.status.idle": "2025-08-21T05:28:54.033890Z",
     "shell.execute_reply": "2025-08-21T05:28:54.033137Z"
    },
    "papermill": {
     "duration": 0.291183,
     "end_time": "2025-08-21T05:28:54.035116",
     "exception": false,
     "start_time": "2025-08-21T05:28:53.743933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create submission dataframe\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'winner_model_a': test_predictions[:, 0],    # Probability model A wins\n",
    "    'winner_model_b': test_predictions[:, 1],    # Probability model B wins  \n",
    "    'winner_tie': test_predictions[:, 2]         # Probability of tie\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9831475",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T05:28:54.652658Z",
     "iopub.status.busy": "2025-08-21T05:28:54.652355Z",
     "iopub.status.idle": "2025-08-21T05:28:54.666595Z",
     "shell.execute_reply": "2025-08-21T05:28:54.665713Z"
    },
    "papermill": {
     "duration": 0.302218,
     "end_time": "2025-08-21T05:28:54.667876",
     "exception": false,
     "start_time": "2025-08-21T05:28:54.365658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability sums (should be ~1.0): count    3.0\n",
      "mean     1.0\n",
      "std      0.0\n",
      "min      1.0\n",
      "25%      1.0\n",
      "50%      1.0\n",
      "75%      1.0\n",
      "max      1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Verify probabilities sum to 1 (they should due to softmax)\n",
    "prob_sums = submission[['winner_model_a', 'winner_model_b', 'winner_tie']].sum(axis=1)\n",
    "print(f\"Probability sums (should be ~1.0): {prob_sums.describe()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75a247d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T05:28:55.309609Z",
     "iopub.status.busy": "2025-08-21T05:28:55.309370Z",
     "iopub.status.idle": "2025-08-21T05:28:55.318315Z",
     "shell.execute_reply": "2025-08-21T05:28:55.317634Z"
    },
    "papermill": {
     "duration": 0.320135,
     "end_time": "2025-08-21T05:28:55.319392",
     "exception": false,
     "start_time": "2025-08-21T05:28:54.999257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submission preview:\n",
      "        id  winner_model_a  winner_model_b  winner_tie\n",
      "0   136060        0.255210        0.207396    0.537394\n",
      "1   211333        0.559739        0.328630    0.111631\n",
      "2  1233961        0.294327        0.404701    0.300972\n"
     ]
    }
   ],
   "source": [
    "# Display submission\n",
    "print(\"\\nSubmission preview:\")\n",
    "print(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c4afa13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T05:28:55.951233Z",
     "iopub.status.busy": "2025-08-21T05:28:55.950984Z",
     "iopub.status.idle": "2025-08-21T05:28:55.959799Z",
     "shell.execute_reply": "2025-08-21T05:28:55.959015Z"
    },
    "papermill": {
     "duration": 0.299135,
     "end_time": "2025-08-21T05:28:55.960974",
     "exception": false,
     "start_time": "2025-08-21T05:28:55.661839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submission saved as 'submission.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save submission\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"\\nSubmission saved as 'submission.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e263ee6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T05:28:56.581906Z",
     "iopub.status.busy": "2025-08-21T05:28:56.581476Z",
     "iopub.status.idle": "2025-08-21T05:28:56.590171Z",
     "shell.execute_reply": "2025-08-21T05:28:56.589280Z"
    },
    "papermill": {
     "duration": 0.346098,
     "end_time": "2025-08-21T05:28:56.591316",
     "exception": false,
     "start_time": "2025-08-21T05:28:56.245218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction statistics:\n",
      "Average probabilities by class:\n",
      "Model A wins: 0.370\n",
      "Model B wins: 0.314\n",
      "Tie: 0.317\n",
      "\n",
      "Most confident predictions:\n",
      "Most confident prediction (ID 211333):\n",
      "  Model A: 0.560\n",
      "  Model B: 0.329\n",
      "  Tie: 0.112\n"
     ]
    }
   ],
   "source": [
    "# Additional analysis\n",
    "print(\"\\nPrediction statistics:\")\n",
    "print(\"Average probabilities by class:\")\n",
    "print(f\"Model A wins: {submission['winner_model_a'].mean():.3f}\")\n",
    "print(f\"Model B wins: {submission['winner_model_b'].mean():.3f}\")\n",
    "print(f\"Tie: {submission['winner_tie'].mean():.3f}\")\n",
    "\n",
    "print(\"\\nMost confident predictions:\")\n",
    "max_probs = submission[['winner_model_a', 'winner_model_b', 'winner_tie']].max(axis=1)\n",
    "confident_idx = max_probs.idxmax()\n",
    "print(f\"Most confident prediction (ID {submission.loc[confident_idx, 'id']}):\")\n",
    "print(f\"  Model A: {submission.loc[confident_idx, 'winner_model_a']:.3f}\")\n",
    "print(f\"  Model B: {submission.loc[confident_idx, 'winner_model_b']:.3f}\")\n",
    "print(f\"  Tie: {submission.loc[confident_idx, 'winner_tie']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7926bacc",
   "metadata": {
    "papermill": {
     "duration": 0.282971,
     "end_time": "2025-08-21T05:28:57.160060",
     "exception": false,
     "start_time": "2025-08-21T05:28:56.877089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e0387ed",
   "metadata": {
    "papermill": {
     "duration": 0.286725,
     "end_time": "2025-08-21T05:28:57.728138",
     "exception": false,
     "start_time": "2025-08-21T05:28:57.441413",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9809560,
     "isSourceIdPinned": false,
     "sourceId": 86518,
     "sourceType": "competition"
    },
    {
     "datasetId": 1868899,
     "sourceId": 3052421,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1392.016686,
   "end_time": "2025-08-21T05:29:01.701687",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-21T05:05:49.685001",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
