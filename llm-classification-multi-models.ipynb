{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1495f6fb",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-12T07:11:29.124929Z",
     "iopub.status.busy": "2025-08-12T07:11:29.124558Z",
     "iopub.status.idle": "2025-08-12T07:11:31.015418Z",
     "shell.execute_reply": "2025-08-12T07:11:31.014457Z"
    },
    "papermill": {
     "duration": 1.898617,
     "end_time": "2025-08-12T07:11:31.016928",
     "exception": false,
     "start_time": "2025-08-12T07:11:29.118311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/llm-classification-finetuning/sample_submission.csv\n",
      "/kaggle/input/llm-classification-finetuning/train.csv\n",
      "/kaggle/input/llm-classification-finetuning/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1602a8e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T07:11:31.026644Z",
     "iopub.status.busy": "2025-08-12T07:11:31.026234Z",
     "iopub.status.idle": "2025-08-12T07:11:35.007017Z",
     "shell.execute_reply": "2025-08-12T07:11:35.005989Z"
    },
    "papermill": {
     "duration": 3.987457,
     "end_time": "2025-08-12T07:11:35.008732",
     "exception": false,
     "start_time": "2025-08-12T07:11:31.021275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train_df = pd.read_csv('/kaggle/input/llm-classification-finetuning/train.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/llm-classification-finetuning/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f1304e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T07:11:35.018599Z",
     "iopub.status.busy": "2025-08-12T07:11:35.017909Z",
     "iopub.status.idle": "2025-08-12T07:11:35.033936Z",
     "shell.execute_reply": "2025-08-12T07:11:35.033056Z"
    },
    "papermill": {
     "duration": 0.022272,
     "end_time": "2025-08-12T07:11:35.035380",
     "exception": false,
     "start_time": "2025-08-12T07:11:35.013108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (57477, 9)\n",
      "Test shape: (3, 4)\n",
      "Columns: ['id', 'model_a', 'model_b', 'prompt', 'response_a', 'response_b', 'winner_model_a', 'winner_model_b', 'winner_tie']\n",
      "       id             model_a              model_b  \\\n",
      "0   30192  gpt-4-1106-preview           gpt-4-0613   \n",
      "1   53567           koala-13b           gpt-4-0613   \n",
      "2   65089  gpt-3.5-turbo-0613       mistral-medium   \n",
      "3   96401    llama-2-13b-chat  mistral-7b-instruct   \n",
      "4  198779           koala-13b   gpt-3.5-turbo-0314   \n",
      "\n",
      "                                              prompt  \\\n",
      "0  [\"Is it morally right to try to have a certain...   \n",
      "1  [\"What is the difference between marriage lice...   \n",
      "2  [\"explain function calling. how would you call...   \n",
      "3  [\"How can I create a test set for a very rare ...   \n",
      "4  [\"What is the best way to travel from Tel-Aviv...   \n",
      "\n",
      "                                          response_a  \\\n",
      "0  [\"The question of whether it is morally right ...   \n",
      "1  [\"A marriage license is a legal document that ...   \n",
      "2  [\"Function calling is the process of invoking ...   \n",
      "3  [\"Creating a test set for a very rare category...   \n",
      "4  [\"The best way to travel from Tel Aviv to Jeru...   \n",
      "\n",
      "                                          response_b  winner_model_a  \\\n",
      "0  [\"As an AI, I don't have personal beliefs or o...               1   \n",
      "1  [\"A marriage license and a marriage certificat...               0   \n",
      "2  [\"Function calling is the process of invoking ...               0   \n",
      "3  [\"When building a classifier for a very rare c...               1   \n",
      "4  [\"The best way to travel from Tel-Aviv to Jeru...               0   \n",
      "\n",
      "   winner_model_b  winner_tie  \n",
      "0               0           0  \n",
      "1               1           0  \n",
      "2               0           1  \n",
      "3               0           0  \n",
      "4               1           0  \n"
     ]
    }
   ],
   "source": [
    "# Basic info\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "\n",
    "# See columns\n",
    "print(f\"Columns: {list(train_df.columns)}\")\n",
    "\n",
    "# Look at first few rows\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb9d591b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T07:11:35.046428Z",
     "iopub.status.busy": "2025-08-12T07:11:35.046079Z",
     "iopub.status.idle": "2025-08-12T07:11:35.055067Z",
     "shell.execute_reply": "2025-08-12T07:11:35.054035Z"
    },
    "papermill": {
     "duration": 0.016992,
     "end_time": "2025-08-12T07:11:35.056531",
     "exception": false,
     "start_time": "2025-08-12T07:11:35.039539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "As percentages:\n",
      "Model A wins: 34.9%\n",
      "Model B wins: 34.2%\n",
      "Ties: 30.9%\n"
     ]
    }
   ],
   "source": [
    "# Check target distribution\n",
    "# As percentages\n",
    "total = len(train_df)\n",
    "print(f\"\\nAs percentages:\")\n",
    "print(f\"Model A wins: {train_df['winner_model_a'].sum() / total * 100:.1f}%\")\n",
    "print(f\"Model B wins: {train_df['winner_model_b'].sum() / total * 100:.1f}%\")\n",
    "print(f\"Ties: {train_df['winner_tie'].sum() / total * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d41d6462",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T07:11:35.066679Z",
     "iopub.status.busy": "2025-08-12T07:11:35.066358Z",
     "iopub.status.idle": "2025-08-12T07:11:35.102418Z",
     "shell.execute_reply": "2025-08-12T07:11:35.101418Z"
    },
    "papermill": {
     "duration": 0.043004,
     "end_time": "2025-08-12T07:11:35.103993",
     "exception": false,
     "start_time": "2025-08-12T07:11:35.060989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                0\n",
      "model_a           0\n",
      "model_b           0\n",
      "prompt            0\n",
      "response_a        0\n",
      "response_b        0\n",
      "winner_model_a    0\n",
      "winner_model_b    0\n",
      "winner_tie        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a99ecbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T07:11:35.113660Z",
     "iopub.status.busy": "2025-08-12T07:11:35.113366Z",
     "iopub.status.idle": "2025-08-12T07:11:37.695036Z",
     "shell.execute_reply": "2025-08-12T07:11:37.694161Z"
    },
    "papermill": {
     "duration": 2.588527,
     "end_time": "2025-08-12T07:11:37.696803",
     "exception": false,
     "start_time": "2025-08-12T07:11:35.108276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "import xgboost as xgb\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b798efe5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T07:11:37.707581Z",
     "iopub.status.busy": "2025-08-12T07:11:37.706731Z",
     "iopub.status.idle": "2025-08-12T07:11:37.717890Z",
     "shell.execute_reply": "2025-08-12T07:11:37.716980Z"
    },
    "papermill": {
     "duration": 0.018267,
     "end_time": "2025-08-12T07:11:37.719535",
     "exception": false,
     "start_time": "2025-08-12T07:11:37.701268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_advanced_features(df):\n",
    "    print(\"Creating features...\")\n",
    "    \n",
    "    # Basic length features\n",
    "    df['prompt_length'] = df['prompt'].str.len()\n",
    "    df['response_a_length'] = df['response_a'].str.len()\n",
    "    df['response_b_length'] = df['response_b'].str.len()\n",
    "    df['length_diff'] = df['response_a_length'] - df['response_b_length']\n",
    "    df['length_ratio'] = df['response_a_length'] / (df['response_b_length'] + 1)\n",
    "    \n",
    "    # Word counts\n",
    "    df['response_a_words'] = df['response_a'].str.split().str.len()\n",
    "    df['response_b_words'] = df['response_b'].str.split().str.len()\n",
    "    df['word_diff'] = df['response_a_words'] - df['response_b_words']\n",
    "    \n",
    "    # Sentence counts\n",
    "    df['response_a_sentences'] = df['response_a'].str.count(r'[.!?]+')\n",
    "    df['response_b_sentences'] = df['response_b'].str.count(r'[.!?]+')\n",
    "    df['sentence_diff'] = df['response_a_sentences'] - df['response_b_sentences']\n",
    "    \n",
    "    # Question marks (helpfulness)\n",
    "    df['response_a_questions'] = df['response_a'].str.count(r'\\?')\n",
    "    df['response_b_questions'] = df['response_b'].str.count(r'\\?')\n",
    "    df['question_diff'] = df['response_a_questions'] - df['response_b_questions']\n",
    "    \n",
    "    # Exclamation marks (enthusiasm)\n",
    "    df['response_a_exclamations'] = df['response_a'].str.count(r'!')\n",
    "    df['response_b_exclamations'] = df['response_b'].str.count(r'!')\n",
    "    df['exclamation_diff'] = df['response_a_exclamations'] - df['response_b_exclamations']\n",
    "    \n",
    "    # Politeness indicators\n",
    "    df['response_a_polite'] = df['response_a'].str.lower().str.contains(r'please|thank|sorry').astype(int)\n",
    "    df['response_b_polite'] = df['response_b'].str.lower().str.contains(r'please|thank|sorry').astype(int)\n",
    "    df['polite_diff'] = df['response_a_polite'] - df['response_b_polite']\n",
    "    \n",
    "    # Code indicators\n",
    "    df['response_a_code'] = df['response_a'].str.contains(r'```|def |import |class |function').astype(int)\n",
    "    df['response_b_code'] = df['response_b'].str.contains(r'```|def |import |class |function').astype(int)\n",
    "    df['code_diff'] = df['response_a_code'] - df['response_b_code']\n",
    "    \n",
    "    # Average word length (complexity indicator)\n",
    "    df['response_a_avg_word_len'] = df['response_a_length'] / (df['response_a_words'] + 1)\n",
    "    df['response_b_avg_word_len'] = df['response_b_length'] / (df['response_b_words'] + 1)\n",
    "    df['avg_word_len_diff'] = df['response_a_avg_word_len'] - df['response_b_avg_word_len']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e01ae140",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T07:11:37.729242Z",
     "iopub.status.busy": "2025-08-12T07:11:37.728897Z",
     "iopub.status.idle": "2025-08-12T07:11:50.121011Z",
     "shell.execute_reply": "2025-08-12T07:11:50.119965Z"
    },
    "papermill": {
     "duration": 12.39875,
     "end_time": "2025-08-12T07:11:50.122572",
     "exception": false,
     "start_time": "2025-08-12T07:11:37.723822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating features...\n",
      "Creating features...\n"
     ]
    }
   ],
   "source": [
    "# Create features\n",
    "train_df = create_advanced_features(train_df)\n",
    "test_df = create_advanced_features(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86cdd066",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T07:11:50.133455Z",
     "iopub.status.busy": "2025-08-12T07:11:50.133111Z",
     "iopub.status.idle": "2025-08-12T07:11:50.142729Z",
     "shell.execute_reply": "2025-08-12T07:11:50.141841Z"
    },
    "papermill": {
     "duration": 0.016479,
     "end_time": "2025-08-12T07:11:50.144367",
     "exception": false,
     "start_time": "2025-08-12T07:11:50.127888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PREPARE TARGET\n",
    "train_df['target'] = 0  # model_a wins\n",
    "train_df.loc[train_df['winner_model_b'] == 1, 'target'] = 1  # model_b wins\n",
    "train_df.loc[train_df['winner_tie'] == 1, 'target'] = 2  # tie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e69c655",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T07:11:50.154444Z",
     "iopub.status.busy": "2025-08-12T07:11:50.154106Z",
     "iopub.status.idle": "2025-08-12T07:11:50.160044Z",
     "shell.execute_reply": "2025-08-12T07:11:50.158974Z"
    },
    "papermill": {
     "duration": 0.012841,
     "end_time": "2025-08-12T07:11:50.161538",
     "exception": false,
     "start_time": "2025-08-12T07:11:50.148697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "feature_cols = [\n",
    "    'prompt_length', 'response_a_length', 'response_b_length', 'length_diff', 'length_ratio',\n",
    "    'response_a_words', 'response_b_words', 'word_diff',\n",
    "    'response_a_sentences', 'response_b_sentences', 'sentence_diff',\n",
    "    'response_a_questions', 'response_b_questions', 'question_diff',\n",
    "    'response_a_exclamations', 'response_b_exclamations', 'exclamation_diff',\n",
    "    'response_a_polite', 'response_b_polite', 'polite_diff',\n",
    "    'response_a_code', 'response_b_code', 'code_diff',\n",
    "    'response_a_avg_word_len', 'response_b_avg_word_len', 'avg_word_len_diff'\n",
    "]\n",
    "print(len(feature_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d2929d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T07:11:50.171455Z",
     "iopub.status.busy": "2025-08-12T07:11:50.171156Z",
     "iopub.status.idle": "2025-08-12T07:11:50.186549Z",
     "shell.execute_reply": "2025-08-12T07:11:50.185538Z"
    },
    "papermill": {
     "duration": 0.022306,
     "end_time": "2025-08-12T07:11:50.188276",
     "exception": false,
     "start_time": "2025-08-12T07:11:50.165970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = train_df[feature_cols]\n",
    "y = train_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d9f0381",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T07:11:50.198167Z",
     "iopub.status.busy": "2025-08-12T07:11:50.197780Z",
     "iopub.status.idle": "2025-08-12T07:11:50.285176Z",
     "shell.execute_reply": "2025-08-12T07:11:50.284227Z"
    },
    "papermill": {
     "duration": 0.094283,
     "end_time": "2025-08-12T07:11:50.286899",
     "exception": false,
     "start_time": "2025-08-12T07:11:50.192616",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (45981, 26)\n",
      "Validation set: (11496, 26)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a194057d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T07:11:50.297312Z",
     "iopub.status.busy": "2025-08-12T07:11:50.296974Z",
     "iopub.status.idle": "2025-08-12T07:11:50.303031Z",
     "shell.execute_reply": "2025-08-12T07:11:50.302173Z"
    },
    "papermill": {
     "duration": 0.013078,
     "end_time": "2025-08-12T07:11:50.304634",
     "exception": false,
     "start_time": "2025-08-12T07:11:50.291556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#TRAIN MULTIPLE MODELS\n",
    "\n",
    "models = {}\n",
    "\n",
    "# Model 1: Random Forest\n",
    "models['rf'] = RandomForestClassifier(\n",
    "    n_estimators=200, \n",
    "    max_depth=15, \n",
    "    min_samples_split=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Model 2: XGBoost\n",
    "models['xgb'] = xgb.XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Model 3: Gradient Boosting\n",
    "models['gb'] = GradientBoostingClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Model 4: Logistic Regression\n",
    "models['lr'] = LogisticRegression(\n",
    "    random_state=42,\n",
    "    max_iter=1000,\n",
    "    C=1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "846a171b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T07:11:50.315213Z",
     "iopub.status.busy": "2025-08-12T07:11:50.314752Z",
     "iopub.status.idle": "2025-08-12T07:16:45.640975Z",
     "shell.execute_reply": "2025-08-12T07:16:45.639957Z"
    },
    "papermill": {
     "duration": 295.333805,
     "end_time": "2025-08-12T07:16:45.643003",
     "exception": false,
     "start_time": "2025-08-12T07:11:50.309198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training rf...\n",
      "  rf validation log loss: 1.0414\n",
      "Training xgb...\n",
      "  xgb validation log loss: 1.0457\n",
      "Training gb...\n",
      "  gb validation log loss: 1.0483\n",
      "Training lr...\n",
      "  lr validation log loss: 1.0707\n"
     ]
    }
   ],
   "source": [
    "# Train all models and collect predictions\n",
    "individual_scores = {}\n",
    "val_predictions = {}\n",
    "test_predictions = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Validation predictions\n",
    "    val_pred_proba = model.predict_proba(X_val)\n",
    "    val_predictions[name] = val_pred_proba\n",
    "    \n",
    "    # Test predictions\n",
    "    test_pred_proba = model.predict_proba(test_df[feature_cols])\n",
    "    test_predictions[name] = test_pred_proba\n",
    "    \n",
    "    # Score\n",
    "    score = log_loss(y_val, val_pred_proba)\n",
    "    individual_scores[name] = score\n",
    "    \n",
    "    print(f\"  {name} validation log loss: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "123faad2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T07:16:45.659824Z",
     "iopub.status.busy": "2025-08-12T07:16:45.659496Z",
     "iopub.status.idle": "2025-08-12T07:16:45.672995Z",
     "shell.execute_reply": "2025-08-12T07:16:45.672183Z"
    },
    "papermill": {
     "duration": 0.024338,
     "end_time": "2025-08-12T07:16:45.674973",
     "exception": false,
     "start_time": "2025-08-12T07:16:45.650635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_ensemble_avg = np.mean(list(val_predictions.values()), axis=0)\n",
    "test_ensemble_avg = np.mean(list(test_predictions.values()), axis=0)\n",
    "ensemble_avg_score = log_loss(y_val, val_ensemble_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7174d723",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T07:16:45.691595Z",
     "iopub.status.busy": "2025-08-12T07:16:45.691257Z",
     "iopub.status.idle": "2025-08-12T07:16:45.709348Z",
     "shell.execute_reply": "2025-08-12T07:16:45.708545Z"
    },
    "papermill": {
     "duration": 0.028513,
     "end_time": "2025-08-12T07:16:45.711314",
     "exception": false,
     "start_time": "2025-08-12T07:16:45.682801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted ensemble score: 1.0796\n"
     ]
    }
   ],
   "source": [
    "weights = {}\n",
    "total_weight = 0\n",
    "for name, score in individual_scores.items():\n",
    "    # Lower log loss = better = higher weight\n",
    "    weight = 1 / (score + 0.001)  # Add small value to avoid division by zero\n",
    "    weights[name] = weight\n",
    "    total_weight += weight\n",
    "# Create weighted ensemble\n",
    "val_ensemble_weighted = np.zeros_like(val_ensemble_avg)\n",
    "test_ensemble_weighted = np.zeros_like(test_ensemble_avg)\n",
    "\n",
    "for name, weight in weights.items():\n",
    "    val_ensemble_weighted += weight * val_predictions[name]\n",
    "    test_ensemble_weighted += weight * test_predictions[name]\n",
    "\n",
    "ensemble_weighted_score = log_loss(y_val, val_ensemble_weighted)\n",
    "print(f\"Weighted ensemble score: {ensemble_weighted_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fb57bae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T07:16:45.727781Z",
     "iopub.status.busy": "2025-08-12T07:16:45.727525Z",
     "iopub.status.idle": "2025-08-12T07:16:45.733475Z",
     "shell.execute_reply": "2025-08-12T07:16:45.732547Z"
    },
    "papermill": {
     "duration": 0.015352,
     "end_time": "2025-08-12T07:16:45.734779",
     "exception": false,
     "start_time": "2025-08-12T07:16:45.719427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best approach: rf (score: 1.0414)\n"
     ]
    }
   ],
   "source": [
    "# SELECT BEST APPROACH\n",
    "best_score = min(min(individual_scores.values()), ensemble_avg_score, ensemble_weighted_score)\n",
    "\n",
    "if best_score == ensemble_weighted_score:\n",
    "    print(f\"\\nBest approach: Weighted Ensemble (score: {best_score:.4f})\")\n",
    "    final_predictions = test_ensemble_weighted\n",
    "elif best_score == ensemble_avg_score:\n",
    "    print(f\"\\nBest approach: Average Ensemble (score: {best_score:.4f})\")\n",
    "    final_predictions = test_ensemble_avg\n",
    "else:\n",
    "    best_model = min(individual_scores, key=individual_scores.get)\n",
    "    print(f\"\\nBest approach: {best_model} (score: {best_score:.4f})\")\n",
    "    final_predictions = test_predictions[best_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd541e35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T07:16:45.745497Z",
     "iopub.status.busy": "2025-08-12T07:16:45.745186Z",
     "iopub.status.idle": "2025-08-12T07:16:45.750464Z",
     "shell.execute_reply": "2025-08-12T07:16:45.749653Z"
    },
    "papermill": {
     "duration": 0.012231,
     "end_time": "2025-08-12T07:16:45.751832",
     "exception": false,
     "start_time": "2025-08-12T07:16:45.739601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'winner_model_a': final_predictions[:, 0],\n",
    "    'winner_model_b': final_predictions[:, 1],\n",
    "    'winner_tie': final_predictions[:, 2]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b798bfda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T07:16:45.762510Z",
     "iopub.status.busy": "2025-08-12T07:16:45.762175Z",
     "iopub.status.idle": "2025-08-12T07:16:45.769327Z",
     "shell.execute_reply": "2025-08-12T07:16:45.768395Z"
    },
    "papermill": {
     "duration": 0.014152,
     "end_time": "2025-08-12T07:16:45.770735",
     "exception": false,
     "start_time": "2025-08-12T07:16:45.756583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  winner_model_a  winner_model_b  winner_tie\n",
      "0   136060        0.272180        0.279686    0.448134\n",
      "1   211333        0.533395        0.224764    0.241841\n",
      "2  1233961        0.319080        0.407441    0.273479\n"
     ]
    }
   ],
   "source": [
    "print(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2bc58416",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T07:16:45.781777Z",
     "iopub.status.busy": "2025-08-12T07:16:45.781481Z",
     "iopub.status.idle": "2025-08-12T07:16:45.795469Z",
     "shell.execute_reply": "2025-08-12T07:16:45.794260Z"
    },
    "papermill": {
     "duration": 0.021302,
     "end_time": "2025-08-12T07:16:45.796917",
     "exception": false,
     "start_time": "2025-08-12T07:16:45.775615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability sums (should be close to 1.0): 0    1.0\n",
      "1    1.0\n",
      "2    1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Verify probabilities sum to ~1.0\n",
    "prob_sums = submission[['winner_model_a', 'winner_model_b', 'winner_tie']].sum(axis=1)\n",
    "print(f\"Probability sums (should be close to 1.0): {prob_sums.head()}\")\n",
    "\n",
    "# STEP 2: Save submission file\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9809560,
     "sourceId": 86518,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 322.484298,
   "end_time": "2025-08-12T07:16:46.623669",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-12T07:11:24.139371",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
